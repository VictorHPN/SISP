[net]
# Testing
#batch=1
#subdivisions=1
# Training
batch=64
subdivisions=64
width=416
height=416
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.00261
burn_in=1000

# 2000*n°_classes = 2000*2
max_batches = 4000
policy=steps
# 80%, 90% de max_batches
steps=3200,3600
scales=.1,.1


#weights_reject_freq=1001
#ema_alpha=0.9998
#equidistant_point=1000
#num_sigmas_reject_badlabels=3
#badlabels_rejection_percentage=0.2


[convolutional] #0
batch_normalize=1
filters=32
size=3
stride=2
pad=1
activation=leaky

[convolutional] #1
batch_normalize=1
filters=64
size=3
stride=2
pad=1
activation=leaky

### Inicio da CSP #1

[convolutional] #2 - CSP #1
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky 

[route] #3 - CSP #2
layers=-1
groups=2
group_id=1

[convolutional] #4 - CSP #3
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

[convolutional] #5 - CSP #4
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

[route]  #6 - CSP #5
layers = -1,-2

[convolutional] #7 - CSP #6
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

[route] #8 - CSP #7
layers = -6,-1

### Fim da CSP #1

[maxpool] #9
size=2
stride=2

### Inicio da CSP #2

[convolutional] #10
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[route] #11
layers=-1
groups=2
group_id=1

[convolutional] #12
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

[convolutional] #13
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

[route] #14
layers = -1,-2

[convolutional] #15
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[route] #16
layers = -6,-1

### Fim da CSP #2

[maxpool] #17
size=2
stride=2

### Inicio da CSP #3

[convolutional] #18
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[route] #19
layers=-1
groups=2
group_id=1

[convolutional] #20
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[convolutional] #21
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[route] #22
layers = -1,-2

[convolutional] #23
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[route] #24
layers = -6,-1

### Fim da CSP #3

[maxpool] #25
size=2
stride=2

[convolutional] #26
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

################################## FIM DO BACKBONE

### Inicio do HEAD #1

[convolutional] #27
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional] #28
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[convolutional] #29
size=1
stride=1
pad=1
# filters = (n°_classes + 5)*3
filters=21
activation=linear



[yolo] #30
mask = 3,4,5
anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319
classes=2
num=6
jitter=.3
scale_x_y = 1.05
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
ignore_thresh = .7
truth_thresh = 1
random=0
resize=1.5
nms_kind=greedynms
beta_nms=0.6
#new_coords=1
#scale_x_y = 2.0

### Fim do HEAD #1

### Inicio do FPN

[route] #31
layers = -4

[convolutional] #32
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[upsample] #33
stride=2

[route] #34
layers = -1, 23 # Camada anterior com a camada 23 (CSP #3)

[convolutional] #35
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

### Fim do FPN

### Inicio do HEAD #2

[convolutional] #36
size=1
stride=1
pad=1
filters=21
activation=linear

[yolo] #37
mask = 1,2,3
anchors = 10,14,  23,27,  37,58,  81,82,  135,169,  344,319
classes=2
num=6
jitter=.3
scale_x_y = 1.05
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
ignore_thresh = .7
truth_thresh = 1
random=0
resize=1.5
nms_kind=greedynms
beta_nms=0.6
#new_coords=1
#scale_x_y = 2.0

### Fim do HEAD #2
